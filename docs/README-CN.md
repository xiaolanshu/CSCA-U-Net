# CSCA U-Net: A Channel and Space Compound Attention CNN for Medical Image Segmentation

----

## ç›®å½•
- [CSCA U-Net: A Channel and Space Compound Attention CNN for Medical Image Segmentation](#csca-u-net--a-channel-and-space-compound-attention-cnn-for-medical-image-segmentation)
  * [ç›®å½•](#ç›®å½•)
  * [1. æ¦‚è§ˆ](#1-æ¦‚è§ˆ)
    + [è®ºæ–‡](#è®ºæ–‡)
    + [æ•´ä½“æ¶æ„](#æ•´ä½“æ¶æ„)
    + [Abstract](#abstract)
  * [2. æ•°æ®æ–‡ä»¶](#2-æ•°æ®æ–‡ä»¶)
    + [2.1 æ•°æ®é›†](#21-æ•°æ®é›†)
    + [2.2 è®­ç»ƒå¥½çš„æ¨¡å‹](#22-è®­ç»ƒå¥½çš„æ¨¡å‹)
    + [2.3 è®­ç»ƒå¥½çš„é¢„æµ‹å›¾](#23-è®­ç»ƒå¥½çš„é¢„æµ‹å›¾)
  * [3. å¦‚ä½•è¿è¡Œ](#3-å¦‚ä½•è¿è¡Œ)
    + [3.1 è¿è¡Œç¯å¢ƒ](#31-è¿è¡Œç¯å¢ƒ)
    + [3.2 è®­ç»ƒæ¨¡å‹](#32-è®­ç»ƒæ¨¡å‹)
    + [3.3 æµ‹è¯•æ¨¡å‹å¹¶ç”Ÿæˆé¢„æµ‹å›¾ç‰‡](#33-æµ‹è¯•æ¨¡å‹å¹¶ç”Ÿæˆé¢„æµ‹å›¾ç‰‡)
    + [3.4 è¯„ä¼°æ¨¡å‹](#34-è¯„ä¼°æ¨¡å‹)
  * [4. ç»“æœ](#4-ç»“æœ)
  * [5. å¼•ç”¨](#5-å¼•ç”¨])
  * [6. è‡´è°¢](#6-è‡´è°¢)
  * [7. è”ç³»æ–¹å¼](#7-è”ç³»æ–¹å¼)

<small><i><a href='http://ecotrust-canada.github.io/markdown-toc/'>Table of contents generated with markdown-toc</a></i></small>

---

## 1. æ¦‚è§ˆ

### è®ºæ–‡

æˆ‘ä»¬çš„è®ºæ–‡"CSCA U-Net: A Channel and Space Compound Attention CNN for Medical Image Segmentation" å‘è¡¨åœ¨ Artificial Intelligence in Medicine.(è¯¦æƒ…è¯·çœ‹, [papers](https://www.sciencedirect.com/science/article/abs/pii/S0933365724000423))

### æ•´ä½“æ¶æ„

![image-architecture](https://picture-for-upload.oss-cn-beijing.aliyuncs.com/img/image-20221208100223315.png)

### Abstract

<p align = "justify"> 
Image segmentation is one of the vital steps in medical image analysis. A large number of methods based on convolutional neural networks have emerged, which can extract abstract features from multiple-modality medical images, learn valuable information that is difficult to recognize by humans, and obtain more reliable results than traditional image segmentation approaches. U-Net, due to its simple structure and excellent performance, is widely used in medical image segmentation. In this paper, to further improve the performance of U-Net, we propose a channel and space compound attention (CSCA) convolutional neural network, abbreviated CSCA U-Net, which increases the network depth and employs a double squeeze-and-excitation (DSE) block in the bottleneck layer to enhance feature extraction and obtain more high-level semantic features. Moreover, the characteristics of the proposed method are three-fold: (1) channel and space compound attention (CSCA) block, (2) cross-layer feature fusion (CLFF), and (3) deep supervision (DS). Extensive experiments on several available medical image datasets, including Kvasir-SEG, CVC-ClinicDB, CVC-ColonDB, ETIS, CVC-T, 2018 Data Science Bowl (2018 DSB), ISIC 2018 Challenge, and JSUAH-Cerebellum, show that CSCA U-Net achieves competitive results and significantly improves the generalization performance.
</p>

## 2. æ•°æ®æ–‡ä»¶

### 2.1 æ•°æ®é›†

æˆ‘ä»¬åœ¨è¿™ä¸€ç« èŠ‚æä¾›äº†è®ºæ–‡æ‰€ä½¿ç”¨çš„å…¬å…±æ•°æ®é›†. 

- æ¯è‚‰æ•°æ®é›† (åŒ…æ‹¬ Kvasir-SEG, CVC-ClinicDB, CVC-ColonDB, ETIS, and CVC-300.) \[[From PraNet](https://github.com/DengPingFan/PraNet)\]:
  - Total: \[[Aliyun](http://little-shu.com:5244/Aliyun/CSCAUNet/Datasets/Polyp%205%20Datasets.zip)\], \[[Baidu]( https://pan.baidu.com/s/1q5I2e2bbwXdW4evJdCAUpg?pwd=1111)\]
  - TrainDataset: \[[Google Drive](https://drive.google.com/file/d/1lODorfB33jbd-im-qrtUgWnZXxB94F55/view?usp=sharing)\] 
  - TestDataset: \[[Google Drive](https://drive.google.com/file/d/1lODorfB33jbd-im-qrtUgWnZXxB94F55/view?usp=sharing)\]
- 2018 Data Science Bowl: \[[Aliyun](http://little-shu.com:5244/Aliyun/CSCAUNet/Datasets/bowl.zip)\], \[[Baidu](https://pan.baidu.com/s/1JUzWDQydjj83GbniRgstOQ?pwd=1111)\], \[[Google Drive](https://drive.google.com/file/d/1IWoWItLWvj1r2SbJWfBQTyPI0AngEwbb/view?usp=share_link)\]
- ISIC 2018 (åŸå§‹çš„å›¾ç‰‡æ¥è‡ªäº \[[kaggle](https://www.kaggle.com/datasets/pengyizhou/isic2018segmentation/download?datasetVersionNumber=1)\], ä¸è¿‡æˆ‘å°†åŸæœ¬çš„`.tiff`æ ¼å¼çš„å›¾ç‰‡è½¬æ¢æˆäº†`.png`): \[[Aliyun](http://little-shu.com:5244/Aliyun/CSCAUNet/Datasets/ISIC2018.zip)\], \[[Baidu](https://pan.baidu.com/s/1utewXZ8Rs-X5FbTtzOy7DQ?pwd=1111)\], \[[Google Drive](https://drive.google.com/file/d/1qSNXHtV526yLLVyayOsA3bSA9LSSPBrQ/view?usp=share_link)\]

###  2.2 è®­ç»ƒå¥½çš„æ¨¡å‹

\[[Aliyun](http://little-shu.com:5244/Aliyun/CSCAUNet/snapshots.zip)\], \[[Baidu](https://pan.baidu.com/s/15QcH5fBU4uU0w-X3xu24cw?pwd=1111)\], \[[Google Drive](https://drive.google.com/drive/folders/1GvMXm5fehYbMFfC1mV0wHy0rHk_35JUP?usp=share_link)\]

### 2.3 è®­ç»ƒå¥½çš„é¢„æµ‹å›¾

\[[Aliyun](http://little-shu.com:5244/Aliyun/CSCAUNet/Predict_map.zip)\], \[[Baidu](https://pan.baidu.com/s/1KmCXEPkAx5x1QhEx-Utypg?pwd=1111)\], \[[Google Drive](https://drive.google.com/drive/folders/1VA6J9k5XdkanpkMh4IuXe6wg0OS0lUxq?usp=sharing)\]

## 3. å¦‚ä½•è¿è¡Œ

### 3.1 è¿è¡Œç¯å¢ƒ

é¦–å…ˆï¼Œä½ éœ€è¦æœ‰ä¸€ä¸ª`pytorch`çš„ç¯å¢ƒï¼Œæˆ‘ä½¿ç”¨çš„æ˜¯`pytorch 1.10` , ä¸è¿‡ä½¿ç”¨è¾ƒä½ç‰ˆæœ¬çš„åº”è¯¥ä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œå…·ä½“æƒ…å†µè‡ªè¡Œç”„åˆ«ã€‚

ä¹Ÿå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼Œåˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒ (æ³¨æ„: æ­¤è™šæ‹Ÿç¯å¢ƒåä¸º`pytorch`ï¼Œå¦‚æœä½ çš„ç³»ç»Ÿä¸­å·²ç»æœ‰æ­¤åç§°çš„è™šæ‹Ÿç¯å¢ƒï¼Œä½ éœ€è¦æ‰‹åŠ¨æ›´æ”¹ä¸‹`environment.yml`)ï¼š

```shell
conda env create -f docs/enviroment.yml
```

### 3.2 è®­ç»ƒæ¨¡å‹

ä½ å¯ä»¥ç›´æ¥è¿è¡Œä»¥ä¸‹çš„å‘½ä»¤:

```shell
sh run.sh ### use stepLR
sh run_cos.sh ### use CosineAnnealingLR 
```

å¦‚æœä½ åªæƒ³è¿è¡Œå•ä¸ªçš„æ•°æ®é›†ï¼Œå¯ä»¥æ³¨é‡Šæ‰`sh`æ–‡ä»¶ä¸­ä¸ç›¸å…³çš„ä¸€éƒ¨åˆ†ï¼Œæˆ–è€…ç›´æ¥åœ¨å‘½ä»¤è¡Œè¾“å…¥ç±»ä¼¼å¦‚ä¸‹å‘½ä»¤:

```shell
python Train.py --model_name CSCAUNet --epoch 121 --batchsize 16 --trainsize 352 --train_save CSCAUNet_Kvasir_1e4_bs16_e120_s352 --lr 0.0001 --train_path $dir/data/TrainDataset --test_path $dir/data/TestDataset/Kvasir/  # you need replace ur truely Datapath to $dir.
```

### 3.3 æµ‹è¯•æ¨¡å‹å¹¶ç”Ÿæˆé¢„æµ‹å›¾ç‰‡

å¦‚æœä½ ä½¿ç”¨äº†`sh` æ–‡ä»¶è¿›è¡Œè®­ç»ƒï¼Œå®ƒä¼šåœ¨è®­ç»ƒå®Œæˆåè¿›è¡Œæµ‹è¯•ã€‚

å¦‚æœä½ ä½¿ç”¨äº†`python`å‘½ä»¤è¿›è¡Œè®­ç»ƒï¼Œä½ ä¹Ÿå¯ä»¥æ³¨é‡Šæ‰`sh`æ–‡ä»¶ä¸­æœ‰å…³è®­ç»ƒçš„éƒ¨åˆ†ï¼Œæˆ–è€…ç›´æ¥åœ¨å‘½ä»¤è¡Œè¾“å…¥ç±»ä¼¼å¦‚ä¸‹å‘½ä»¤:

```shell
python Test.py --train_save CSCAUNet_Kvasir_1e4_bs16_e120_s352 --testsize 352 --test_path $dir/data/TestDataset
```

### 3.4 è¯„ä¼°æ¨¡å‹

- å¦‚æœæ˜¯è¯„ä¼°æ¯è‚‰æ•°æ®é›†ï¼Œä½ å¯ä»¥ä½¿ç”¨`eval`ä¸­çš„`matlab`ä»£ç ï¼Œæˆ–è€…ä½¿ç”¨ \[[UACANet](https://github.com/plemeri/UACANet)\] æä¾›çš„è¯„ä¼°ä»£ç ã€‚
- å¦‚æœæ˜¯å…¶ä»–çš„æ•°æ®é›†ï¼Œä½ å¯ä»¥ä½¿ç”¨`evaldata`ä¸­çš„ä»£ç ã€‚
- ä¹‹æ‰€ä»¥ä½¿ç”¨ä¸åŒçš„è¯„ä¼°ä»£ç ï¼Œæ˜¯å› ä¸ºè¦ä¸åœ¨æ•°æ®é›†ä¸Šåšå®éªŒçš„å…¶å®ƒè®ºæ–‡åœ¨è¯„ä¼°æ—¶ä½¿ç”¨ç›¸åŒçš„æ–¹æ³•ã€‚

## 4. ç»“æœ
- Polyp Datasets
	![20221208101511](https://picture-for-upload.oss-cn-beijing.aliyuncs.com/img/20221208101511.png)
	
	![20221208101543](https://picture-for-upload.oss-cn-beijing.aliyuncs.com/img/20221208101543.png)

- 2018 DSB
	![](https://picture-for-upload.oss-cn-beijing.aliyuncs.com/img/20221208101622.png)

- ISIC 2018
	![](https://picture-for-upload.oss-cn-beijing.aliyuncs.com/img/20221208101638.png)

- JSUAH-Cerebellum 
	![20221208101600](https://picture-for-upload.oss-cn-beijing.aliyuncs.com/img/20221208101600.png)

- Qualitative Results
  
  - Polyp Segmentation 
  ![display-polyp](https://picture-for-upload.oss-cn-beijing.aliyuncs.com/img/display-polyp.png)
  - 2018 DSB
  ![display-DSB](https://picture-for-upload.oss-cn-beijing.aliyuncs.com/img/display-DSB.png)
  - ISIC 2018
  ![display-ISIC2](https://picture-for-upload.oss-cn-beijing.aliyuncs.com/img/display-ISIC-comressed.png)
  - Fetal Ultrasound ï¼ˆPrivateï¼‰ 
  ![display-self](https://picture-for-upload.oss-cn-beijing.aliyuncs.com/img/display-self.png)

## 5. å¼•ç”¨

å¦‚æœæ‚¨è§‰å¾—è¿™é¡¹å·¥ä½œå¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼Œè¯·æ‚¨å¼•ç”¨å®ƒï¼š
```
@article{shu2024102800,
title = {CSCA U-Net: A channel and space compound attention CNN for medical image segmentation},
journal = {Artificial Intelligence in Medicine},
volume = {150},
pages = {102800},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102800},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724000423},
author = {Xin Shu and Jiashu Wang and Aoping Zhang and Jinlong Shi and Xiao-Jun Wu},
keywords = {U-net, Channel and spatial compound attention, Cross-layer feature fusion, Deep supervision, Medical image segmentation}
}
```


## 6. è‡´è°¢

- æœ¬æ–‡çš„å¾ˆå¤šè®­ç»ƒç­–ç•¥ã€æ•°æ®é›†å’Œè¯„ä¼°æ–¹æ³•éƒ½åŸºäº [PraNet](https://github.com/DengPingFan/PraNet)ã€‚æˆ‘å¯¹èŒƒç™»å¹³åšå£«ç­‰ä½œè€…çš„å¼€æºç²¾ç¥è¡¨ç¤ºé’¦ä½©ï¼Œå¹¶éå¸¸æ„Ÿè°¢`PraNet`è¿™é¡¹å·¥ä½œæä¾›åˆ°çš„å¸®åŠ©ã€‚

## 7. è”ç³»æ–¹å¼

- ğŸ“« Email: vegas_tyler@outlook.com

- <img src="https://picture-for-upload.oss-cn-beijing.aliyuncs.com/img/qq.svg" width="20" height="20"> QQ: 872845991
